# Chapter15. 구글 드라이브 설계

## 1단계: 문제 이해 및 설정 범위 확정

- 파일 업로드/다운로드, 파일 동기화, 알림(notification) 지원해야함.

- 여러 단말에 파일 동기화 지원.

- 파일 크기 제한 10GB

- 일간 능동 사용자(DAU) 10Million.

- 파일 갱신 이력 조회

- 파일 공유

- 파일 편집되거나 삭제되거나 새롭게 공유되었을 때 알림 표시.

### 논의하지 않을 것

- 구글 문서 편집 및 협업 : 여러 사용자가 동시에 편집하는 기능은 설계 범위에서 제외

### 기능적 요구 사항 외에 비기능적 요구사항

- 안정성: 데이터 손실 발생하면 안됨.

- 빠른 동기화 속도: 파일 동기화에 너무 많은 시간이 소요되면 사용자는 인내심을 잃고 더 이상 사용하지 않음.

- 네트워크 대역폭: 많은 대역폭을 잡아먹으면 모바일에서 사용이 어렵다.

- 규모 확장성: 아주 많은 양의 트래픽 처리도 가능해야함.

- 높은 가용성: 서버 장애 / 느려짐 / 네트워크가 끊겨도 시스템은 계속 사용 가능해야함.

### 개략적 추정치

- 가입 사용자는 오천만(5 Million)이고, DAU 천만명

- 모든 사용자에게 10GB 무료 저장 공간 할당

- 매일 각 사용자가 평균 2개 파일 업로드. 파일 평균 크기 500KB

- 읽기:쓰기 비율 1:1

- 필요 저장공간 총량 = 5M x 10GB = 500PB

- 업로드 API QPS = 1M x 2회 업로드 / 24h / 3600s = 약 240

- 최대 QPS = QPS x 2 = 480

## 2단계 : 개략적 설계안 제시 및 동의 구하기

- 첫 시작은 동일하게 모든 것을 담은 서버 한 대에서 출발해 천만 사용자 지원이 가능한 시스템으로 발전시켜 나가는 것.

  - 파일을 올리고 다운로드하는 과정을 처리할 웹 서버

  - 사용자 데이터, 로그인 정보, 파일 정보 등의 메타 데이터를 보관할 데이터베이스

  - 파일을 저장할 저장소. 파일 저장을 위해 1TB의 공간 사용할 것.

### API

- 모두 HTTPS 프로토콜 사용해야함.
- SSL 지원 프로토콜 사용 목적은 클라이언트-백엔드 서버가 주고 받는 데이터 보호 목적.

1. 파일 업로드 API

- 단순 업로드: 파일 크기가 작을 때 사용.
- 이어 올리기(resumable upload): 파일 사이즈가 크고 네트워크 문제로 업로드가 중단될 가능성이 높다고 생각되면 사용.

2. 파일 다운로드 API

3. 파일 갱신 히스토리 API

### 한대 서버 제약 극복

- 업로드되는 파일이 많아지면 파일 시스템이 가득 참.

- 가장 먼저 떠오르는 해결책은 데이터 샤딩(sharding)으로 여러 서버에 나눠 저장.

- 로드밸런서: 네트워크 트래픽 분산. 특정 웹 서버에 장애가 발생하면 자동으로 해당 서버 우회

- 웹 서버: 로드밸런서 추가 이후 더 많은 웹서버 손쉽게 추가 가능

- 메타데이터 데이터베이스: 데이터베이스를 파일 저장 서버에 분리해서 SPOF 회피

- 파일 저장소: S3를 파일 저장소로 사용.

### 동기화 충돌

- 기본적인 접근 전략: 먼저 처리되는 변경을 성공, 나중 처리 변경을 충돌 발생으로 처리

- 오류 발생 시점에 이 시스템에는 같은 파일의 두 가지 버전이 존재 -> 어떻게 해결할 것인가?

  - 직접적인 해결 방법에 대한 언급은 존재하지 않음.

### 개략적 설계안

- 사용자 단말

- 블록 저장소 서버

  - 파일을 여러 개의 블록으로 나눠 저장, 각 블록에는 고유한 해시값이 할당

  - 이 해시값은 메타데이터 데이터베이스에 저장

  - 각 블록은 독립적인 객체로 취급되며 클라우드 저장소 시스템 (본 설계에선 S3)에 보관

  - 예시한 설계안의 경우, 한 블록은 드롭박스 살를 참고해서 최대 4MB로 지정

- 아카이빙 저장소(Cold Storage)

- 로드밸런서

- API 서버

- 메타데이터 데이터베이스

- 메타데이터 캐시

- 알림 서비스: 특정 이벤트가 발생했음을 클라이언트에게 알리는데 쓰이는 발생/구독 프로토콜 기반 시스템

- 오프라인 사용자 백업 큐 : 클라이언트가 접속 중이 아니라서 파일의 최신 상태를 확인할 수 없을 때는 해당 정보를 이 큐에 두어 나중에 클라이언트가 접속했을 때 동기화

## 3단계 : 상세 설계

### 블록 저장소 서버

- 정기적으로 갱신되는 큰 파일들은 업데이트 일어날 때마다 전체 파일을 서버로 보내면 네트워크 대역폭 많이 잡아먹음.

- 최적화 전략 2가지

  - 델타 동기화 : 파일이 수정되면 전체 파일 대신 수정이 일어난 블록만 동기화

  - 압축 : 블록 단위로 압축해 두면, 데이터 크기를 많이 줄일 수 있다.

    - 텍스트 파일 압축할 땐 gzip or bzip2 사용, 이미지 또는 비디오 압축할 때는 다른 압축 알고리즘 사용.

### 높은 일관성 요구 사항

- 강한 일관성 모델이 기본으로 지원되어야함.

- 캐시에 보관된 사본과 데이터베이스에 있는 원본(master)이 일치

- 데이터베이스에 보관된 원본에 변경이 발생하면 캐시에 있는 사본을 무효화.

- RDBMS에선 강한 일관성 지원, NoSQL은 동기화 로직 안에 프로그램해서 넣어야함.

### 메타데이터 데이터베이스

- 유저, 디바이스, 네임스페이스, 파일, 파일 버전, 블록 정보를 보관하는 DB

### 업로드 절차

- 파일 메타 데이터 추가

- 파일을 클라우드 저장소에 업로드

### 다운로드 절차

- 파일이 새로 추가되거나 편집되면 자동으로 시작.

- 클라이언트가 다른 클라이언트로부터 파일을 편집하거나 추가했다는 사실 감지하는 방법

  - 클라이언트 A가 접속 중 다른 클라이언트로부터 파일이 변경되면 알림 서비스가 클라이언트 A에게 변경 알림.

  - 클라이언트 A가 네트워크 연결 상태가 아닌 경우, 데이터 캐시에 보관. 클라이언트 접속 상태가 접속 중으로 바뀌면 그 때 해당 클라이언트는 새 버전 가져감.

### 알림 서비스

- 롤 폴링. 드롭박스 채택

- 웹소켓, 클라이언트와 서버 사이에 지속적인 통신 채널 제공.

  - 이 서비스에서는 채택 X

  - 본 시스템 설계에서 양방향 통신 필요하지 않음.

  - 서버는 파일 변경 사실을 클라이언트에게 알려줘야하지만, 반대는 요구되지 않음.

### 저장소 공간 절약

- 중복 제거

- 지능적 백업 전략

  - 한도 설정: 보관해야하는 파일 버전 갯수 상한선

  - 중요한 버전만 보관

- 자주 쓰지 않는 데이터는 아카이빙 저장소로 이전. (S3-> Glacier)

### 장애 처리

- 로드밸런서 장애 : 로드밸런서끼리 heartbeat 보내서 상태 모니터링

- 블록 저장소 장애 : 블록 저장소에서 장애 발생 시, 다른 서버가 미완료 상태 또는 대기 상태 작업 받아야함.

- 클라우드 저장소 장애 : 다른 리전으로 옮겨 작업한다. (S3 데이터는 여러 지역에 다중화 되어 있음.)

- API 서버 장애 : 로드 밸런서가 장애 발생한 API 서버에 트래픽 보내지 않음.

- 메타데이터 캐시 장애 : 캐시 서버 다중화.

- 메타데이터 데이터베이스 장애

- 알림 서비스 장애

- 오프라인 사용자 백업 큐 장애: 큐 다중화 필요하다.

## 4단계 : 마무리

### 생각해 볼 것들

- 블록 저장소 서버를 거치지 않고 파일을 클라우드 저장소에 직접 업로드한다면?

  - 파일을 클라우드 저장소로 직접 올리면 업로드 시간은 빨라지나 몇 가지 단점 존재

  - 분할, 압축, 암호화 로직을 클라이언트에 두어야 하므로, 플랫폼별로 따로 구현.

  - 클라이언트 해킹 가능성으로 암호화 로직을 클라이언트 안에 두는 것은 적절하지 않음.
