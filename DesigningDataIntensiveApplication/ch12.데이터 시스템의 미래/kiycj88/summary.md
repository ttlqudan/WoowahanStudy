# chapter 12. 데이터 시스템의 미래

## 데이터 통합
"No silver bullet" - 모든 상황에 맞는 소프트웨어 도구는 없다.

적절하게 통합해서 사용해야 한다.

### 파생 데이터에 특화된 도구의 결합
하나의 데이터베이스로만 애플리케이션을 만들지 않고, 더 복잡하고 다양한 기능을 위해서 파생 데이터를 다루는 다른 데이터 시스템을 통합적으로 구축해서 사용한다.

#### 데이터플로에 대한 추론
데이터의 입력과 출력에 대해서 분명히 해야하고 충분히 고려해야 한다. 예를 들어서 검색색인과 데이터베이스에 직접 데이터베이스를 dual-write하면 in-sync 문제가 발생할 수 있다.

그래서, 파생 데이터 시스템은 이벤트 로그를 기반으로 갱신하면 결정적이고 멱등성을 지녀 유지보수하기 용이하다.

#### 파생데이터 vs 분산 트랜잭션
- 분산 트랜잭션
  - 선형성 보장
- 로그 기반 시스템
  - 비동기기 때문에 선형성 보장 X

하지만, XA는 결함 대응에 취약하고 성능 면에서도 나쁘기 때문에, 대부분의 경우에는 로그 기반 파생데이터가 이기종 데이터 시스템에서 데이터를 통합하는 가장 장래성 있는 접근법이라고 작가는 생각(나도 동의)

비동기 파생 시스템 상에서 더 강력한 보장을 구현하는 몇가지 방법을 설명할 예정.

#### 전체 순서화의 제약
단일 리더 방식으로만 순서를 보장할 수 있는데, 단일 노드에서 처리할 수 있는 양보다 트래픽이 커지면 파티셔닝을 해야 하는데, 이러면 이벤트의 전체 순서는 애매해진다.

이러한 전체 순서를 결정하는 것은 전체 순서 브로드캐스트라고 하는데, 이것은 합의와 동등하다. 대부분의 합의 알고리즘은 단일 노드가 전체 이벤트 스트림을 처리하기에 충분한 처리량을 가정하고 설계되어있다. 그래서 단일 노드를 넘어서는 경우에 대해서는 아직 해결되지 않은 연구과제이다.


#### 인과성 획득을 위한 이벤트 순서화
이벤트간 인과성이 없으면 전체 순서가 정해지지 않더라도 문제가 되지 않는데, 이벤트간 인과성이 있으면 문제가 되는 경우가 있다.
이 문제를 해결할 간단한 방법은 없다.

미래에는 전체 순서 브로드캐스트 병목을 거치지 않고, 인과적 의존성을 효율적으로 해결할 수 있는 개발 패턴이 등장할 것!

### 일괄 처리와 스트림 처리
데이터 통합의 목표는 데이터를 올바른 장소에 올바른 형태로 두는 것!

일괄 처리와 스트림 처리는 입력을 처리해서 올바른 장소에 올바른 형태로 파생데이터 셋을 처리하기 위한 방법

#### 파생 상태 유지
- 일괄 처리는 순수함수를 장려하며 입력을 불변으로 간주하고 출력은 추가 적용으로만 사용한다.
  - 내결함성에도 좋고, 데이터 플로 추론을 단순화 할 수 있다.
- 동기식으로 운용할수도 있지만, 비동기 방식이 더 시스템을 견고하게 하기 떄문에 비동기를 선호.

#### 애플리케이션 발전을 위한 데이터 재처리
일괄 처리를 하면 데이터를 재처리하는 데에 용이한데, 데이터 재처리로 새로운 기능 추가와 변경된 요구사항에 쉽게 대응할 수 있다.
- 새로운 파생뷰 생성
- 점진적으로 발전이 가능
  - 문제 발생시 쉽게 롤백도 가능


#### 람다 아키텍처
일괄처리와 스트림 처리를 조합해서 사용할수 있을까? => ***람다 아키텍처***

람다 아키텍처는 스트림 처리로는 빠르지만 approximate 파생 뷰를 빠르게 반영하고, 이후에 일괄처리로 같은 이벤트를 이용해서 정확한 파생 뷰를 반영하는 것

작가는 몇가지 문제점이 있다고 생각
- 일괄처리와 스트림처리에 같은 로직을 유지해야 하는데 상당한 노력이 필요
- 출력을 병합해야 하는 경우에 대한 어려움
- 일괄처리에서 전체 데이터셋을 재처리하는것은 아주 좋지만, 비용도 크기 때문에 증분처리하는 경우들이 있다. 이런 경우 낙오자 처리 문제가 있을 수 있고, 증분으로 일괄처리를 하면 스트림과 결국 유사한 문제들을 발생시킬 수 있어서 일괄처리의 장점을 잃게 된다.

#### 일괄 처리와 스트림 처리의 통합
최근에는 일괄처리연산과 스트림처리 연산을 모두 구현함으로써 람다 아키텍처의 단점을 빼고 장점만 취할수 있게 하는 작업이 진행되고 있다.

- 최근 이벤트 스트림을 다루는 처리엔진에서 과거 이벤트를 재생하는 능력
- 스트림 처리자에서 사용되는 exactly once semantic
- 처리 시간 기준이 아니라 이벤트 시간 기준으로 윈도우를 처리하는 도구

## 데이터베이스 언번들링
추상화 수준에서 보면 데이터베이스, 하둡, 운영체제는 모두 같은 기능을 수행한다. 핵심은 전부 정보 관리 시스템이라는 점. 

유닉스와 RDB는 정보 관리 문제를 매우 다른 철학으로 접근 
- 유닉스는 파일 단위로 저수준 하드웨어 추상화를 해서 프로그래머에게 제공
- RDB는 레코드 단위로 자료 구조, 동시성, 장애 복구 등의 복잡섬을 감추는 고수준 추상화를 해서 애플리케이션 프로그래머에게 제공  

어느것이 좋을지는 무엇을 원하냐에 따라 다르다. 이 두 철학이 서로 긴장감이 있어왔는데 이 장에서 화해시키고 싶음.

### 데이터 저장소 기술 구성하기
데이터베이스에 내장된 기능과 일괄 처리와 스트림 처리로 구축하는 파생 데이터 시스템 사이에는 유사점이 있다.

#### 색인 생성하기
색인 생성시
- 일관된 스냅숏을 사용해 스캔하고 색인에 기록
- 이후 쓰기는 쓰기 로그를 받아서 처리
이 부분은 CDC와 상당히 유사하다.

#### 모든 것의 메타데이터베이스
이런 관점에서 볼 때 전체 조직의 dataflow가 거대한 데이터베이스처럼 보인다!

파생 데이터 시스템이 등장하면서 이런 도구를 하나로 통합된 데이터베이스 제품의 기능으로 구현하지 않고, 여러 소프트웨어를 사용해서 제공한다.

모든 접근 패턴에 적합한 데이터 모델이나 저장 형식이 없다고 가정하면, 서로 다른 저장소와 처리 도구를 사용하지만 하나의 응집된 시스템으로 구성할수 있는 두가지 길이 있다.
- 연합(federated) 데이터베이스: 읽기를 통합
  - 엄청나게 많은 하단 저장소 엔진과 처리 메서드를 통합해 질의하는 인터페이스를 제공
  - 연합 질의 인터페이스는 고수준 질의 언어와 우아한 시맨틱을 사용하지만 구현이 복잡한 단일 통합 시스템이라는 관계형 데이터베이스의 전통을 따른다.
- 언번들링 데이터베이스: 쓰기를 통합
  - 연합 데이터베이스는 읽기전용으로 질의하는 문제는 해결하지만 여러 시스템에 걸친 쓰기를 동기화하기에는 적합하지 않다.
  - 저장소 시스템들을 색인 유지 기능처럼 다른 기술에 걸친 쓰기를 동기화할수 있는 방식
  - 하나만 잘하는 작은 도구를 사용하는 유닉스 전통을 따른다

#### 언번들링이 동작하게 만들기
쓰기를 동기화하는 방법으로 분산 트랜잭션이 있지만, 별로.. => 비동기 이벤트 로그를 사용하는 것이 훨씬 좋다. 왜냐?
- 장애나 성능 저하가 생겨도 결함이 전파되지 않는다.
- 인적 수준에서 언번들링하면 서비스와 시스템을 각자 개발하고 개선하고 독립적으로 유지보수 가능하다. 
loosely couping하기 때문이라고 요약 가능.

#### 언번들링 vs 통합 시스템
필요한 모든것을 만족하는 단일 기술이 있다면 그 제품을 사용하고, 없으면 언번들링과 합성을 이용하자!

#### 뭐가 빠졌지?
아직까지 유닉스 셸과 동일한 언번들링된 데이터베이스가 존재하지 않는다!
```shell
mysql | elasticsearch
```

### 데이터플로 주변 애플리케이션 설계
언번들링 데이터베이스와 데이터플로의 아이디어 주변에서 애플리케이션을 구축하는 몇가지 방법을 탐구

#### 파생 함수로서의 애플리케이션 코드
데이터셋이 다른데이터셋으로부터 파생될때 변환 함수 몇가지를 거친다.

예시
- 보조색인
- 전문 검색색인
- 머신러닝 시스템
- 캐시

애플리케이션에 특화된 변환이 필요하기 때문에 애플리케이션 코드를 추가할 필요가 있다. 

#### 애플리케이션 코드와 상태의 분리
오늘날 대부분의 웹 애플리케이션은 stateless 서비스로 배포되고, state는 DB에 저장한다. 이렇게 애플리케이션 로직과 state는 분리하는 것이 합리적이다.

#### 데이터플로: 상태 변경과 애플리케이션 코드 간 상호 작용
데이터플로 측면에서 애플리케이션을 생각한다는 것은 애플리케이션 코드와 상태 관리간의 관계를 재조정한다는 의미이다.

CDC 같은 데이터변화를 탐지해서 애플리케이션 코드로 탐지하면, 데이터베이스 내장 함수가 지원하지 않는 커스텀한 처리가 가능하고, 스트림 처리자를 구성해서 데이터플로를 중심으로 대형 시스템을 구축할 수 있다.

#### 스트림 처리자와 서비스
요즘은 MSA처럼 서비스들을 나누고 네트워크로 통신해서 시스템을 구성하는데, 스트림 연산자로 데이터플로 시스템 구성하는 것도 이와 유사하다.
차이점은 마이크로서비스에서는 동기식 요청/응답 communication을 주로 사용하지만, 여기서는 단방향 비동기 메시지 스트림을 사용하는 것.

데이터플로 접근법이 훨씬 빠르고, 다른 서비스 장애에도 잘 버틸수 있지만, 시간 의존성 문제를 해결해야 한다.


### 파생 상태 관찰하기
- write path: 파생데이터셋을 생성하는 과정
- read path: 사용자 요청으로부터 파생 데이터셋을 제공하는 과정
write path와 read path의 트레이드오프를 파악하고 적절하게 구성해야 한다.

#### 구체화뷰와 캐싱
- 색인이 없으면, 항상 full scan 해야 한다 => write path의 작업량은 아주 작고, read path는 아주 크다.
- 모든 질의에 대해서 미리 계산해둔다면 => write path는 아주 크고, read path는 아주 작다

적절하게 가장 많이 질의되는 고정된 질의집합에 대해서 미리 계산해서 캐시로 만들수 있다.

#### 오프라인 대응 가능한 상태 저장 클라이언트
로컬 데이터베이스를 이용하다가, 온라인이 되었을 때 원격 서버와 동기화하는 방법.

#### 상태 변경을 클라이언트에게 푸시하기
브라우저에서는 기본적으로 상태 변경을 다시 서버를 호출하지 않는 이상 알 수 없다.

많은 최신 프로토콜은 HTTP의 기본적은 요청/응답 패턴을 벗어나서, TCP connection을 유지하면서 서버가 브라우조로 메시지를 보내는 방식의 통신채널을 제공하고 있다.
- ex) EventSource API, WebSocket

#### 종단간 이벤트 스트림
stateless client와 요청/응답 방식의 상호작용이 너무 만연하다. 요청/응답 상호작용 방식에서 벗어나 발행/구독 데이터플로 방식으로 시스템을 구축하는 방식으로 변경하는 것도 고려해야 한다.

#### 읽기도 이벤트다
읽기 요청도 이벤트 스트림으로 표현하고 읽기 이벤트와 쓰기 에븐트 모두를 스트림 처리자를 통해 보내는 방법도 가능.
스트림 처리자는 읽기 결과를 출력 스트림으로 방출해 읽기 이벤트에 응답 한다.

=> 위에서 언급한 상태 변경을 클라이언트에 전달하는 방법과 연동하는 것을 생각한 것 같음

## 정확성을 목표로
모두가 신뢰성 있고, 정확한 애플리케이션을 구축하기를 원한다.

여태까지는 전통적으로 트랜잭션 접근법을 사용해왔고, 지금도 사용하고 있다. 

작가는 이것이 최후의 방법이라고 생각하지 않고, 데이터플로 아키텍처 맥락에서 정확성에 관해 생각하는 몇가지 방법을 제안한다

### 데이터베이스에 관한 종단간 논증
애플리케이션이 직렬성 트랜잭션 같은 비교적 강력한 안정석 속성을 지원하는 데이터 시스템을 사용한다고 해서 데이터 유실과 손상이 없을것이라는 보장은 없다.
애플리케이션에서 정확하지 않은 데이터를 기록하거나 삭제하는 버그가 있을 수 있다.

사람은 항상 실수를 하기 마련이다.

#### 연산자의 정확히 한번 실행
메시지 처리중 에러로 인해서 재시도 하면 메시지가 두번 처리되는 문제가 발생할 수 있다. 이를 해결하는 효과적은 방법은 연산을 멱등으로 만드는 것.

#### 중복 억제
메시지 처리 이외에도 여러 중복 제거 패턴이 발생한다.

TCP의 중복 억제는 강력하지만, TCP 연결 문맥에서만 작동한다. 

클라이언트와 데이터베이스에서의 트랜잭션에서도 중복이 발생할수 있다. COMMIT 에서 에러가 발생하고, 재시도를 하면 이는 별도의 트랜잭션으로 인식되기 떄문에 일반적인 중복 제거 멘커니즘이 도움이 되지 않을 수 있다.

또한, 웹서버와 데이터베이스에서의 트랜잭션 문제를 억제하더라도, 웹 브라우저에서와 웹 서버와의 통신 문제로 인한 재시도 요청은 일반적인 중복제거 메커니즘으로는 해결하기 어렵다.

#### 연산 식별자
연산의 고유 식별자를 만들어 요청하면 중복 제거를 할수 있다. 

#### 종단간 논증
최종 사용자 클라이언트로부터 데이터베이스에 이르는 모든 경로에 트랜잭션 식별자를 포함해서 중복 억제를 할 수 있다.

#### 종단 간 사고를 데이터 시스템에 적용하기
애플리케이션이 직렬성 트랜잭션과 같은 비교적 강력한 안정성 속성을 지원하는 데이터 시스템을 사용한다고, 데이터 손실이나 손상이 발생하지 않는다고 말할 수 없다.

애플리케이션 자체가 중복 억제와 같은 종단 간 대책을 갖출 필요가 있다.

트랜잭션은 유용하지만, 충분하지는 않고, 비용이 많이 든다. 

종단간 정확성 속성을 더 쉽게 제공해주고 더 좋은 성능을 제공해주는 내결함성 추상화를 탐구할 필요가 있다.

### 제약 조건 강제하기
#### 유일성 제약 조건은 합의가 필요하다
유일성 제약조건을 강제하기 위해서는 합의가 필요하다. 

이 합의를 달성하는 가장 일반적인 방법은 단일 노드를 리더로 만들고 해당 노드가 모든 결정을 하게끔 책임을 부여하는 것.

유일성 검사는 유일성이 피룡한 값을 기준으로 파티셔닝하면 확장이 가능.

#### 로그 기반 메시징의 유일성
로그 기반에서는 충돌이 발생할 수 있는 쓰기를 모두 같은 파티션으로 라우팅하고 순서대로 처리.

#### 다중 파티션 요청 처리
데이터베이스의 전통적인 접근법에서는 모든 파티션에 걸쳐 원자적 커밋이 필요하다.

파티셔닝된 로그를 사용하면 원자적 커밋 없이 동등한 정확성을 달성 할수 있다.
- 다중 파티션 트랜잭션을 서로 다르게 파티셔닝된 두 단계로 나누고 종단 간 요청 ID를 사용

### 적시성과 무결성
일관성이라는 용어는 두가지 요구사항이 합쳐진것.
- 적시성(Timeliness): 항상 최신 상태로 관측 가능한 것
- 무결성(Integrity): 데이터에 손상이 없는 것.
적시성 위반은 "최종적 일관성", 무결성 위반은 "영구적 불일치"

"무결성이 적시성보다 훨씬 중요하다!!!"

#### 데이터플로 시스템의 정확성
이벤트 기반 데이터플로 시스템의 흥미로운 속성 하나는 적시성과 무결성을 분리하는 것.

#### 느슨하게 해석되는 제약 조건
유일성 제약 조건을 강제하려면 합의가 필요하다. => 제약이 많다.

But, 실제 많은 애플리케이션은 훨씬 완화된 유일성 개념을 사용해 이 제한을 피할 수 있다.
- 보상 트랜잭션
- apology 워크 플로: 재고 이상의 주문이 있을 떄, 소비자에게 배송 지연을 사과하고, 추후 배송
- 항공사에서는 over-booking을 허용하고, 비즈니스적으로 보상
- 계좌 잔고보다 더 많은 돈을 빼면, 초과 인출 수수료를 부과하고 빚진 돈을 갚으라고 요구.
많은 비즈니스 상황에서 제약 조건을 일시적으로 위반하고 나중에 사과해 바라잡는 것은 실제로 수용가능한 방법이다.

이것은 비즈니스적으로 결정 사안이다.

이런 애플리케이션에서 무결성은 ***반드시*** 요구한다. But, 적시성은 반드시 필요한 것은 아니다.

#### 코디네이션 회피 데이터 시스템
종합해보면, 제약조건을 느슨하게 관리하는 방법으로 간다면 코디네이션 회피 방법으로 데이터시스템을 구축할 수 있다. 
그러면 코디네이션 데이터 시스템에 비해서 성능도 더 좋고 더 나은 내결함성을 지닌 시스템을 구축할수 있다.

### 믿어라. 하지만 확인하라.
지금 책에서 말한 문제를 전부 생각한다면 아무것도 할수가 없다. 모든 문제는 확률적 문제이고, 어떤 경우는 거의 발생하지 않는다고 할수 있다.

어떻게 하더라도 데이터 무결성 문제는 발생할 수 있다. 맹목적으로 모든 것이 잘 동작한다고 믿지마라

그렇기 때문에 실제로 확인하고 검증하는 것이 좋다.

## 옳은일 하기
기술은 그 자체로 좋거나 나쁜 것이 아니다. 중요한 것은 기술을 어떻게 사용하고 기술이 어떻게 사람들에게 영향을 주는가다. 

소프트웨어 엔지니어도 윤리적 책임을 져야 한다.