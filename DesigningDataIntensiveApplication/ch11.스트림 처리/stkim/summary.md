# Chapter 11. 스트림 처리

## 1. 들어가기 전에...

- 일괄 처리 문제점은 데이터를 반영하는데 하루 이상이 소요되고, 성격 급한 사용자가 느끼기에는 너무 느림.

- 이벤트가 발생할 때 마다 데이터를 처리하는 구조가 필요함.

- 스트림 처리는 고정된 시간 조각을 완전히 포기하고 각 이벤트가 발생할 때마다 간단히 처리하는 아이디어입니다.

- 시간에 따라 점진적으로 사용 가능한 데이터입니다.

## 2. 이벤트 스트림 전송

- 레코드는 더 일반적으로 이벤트로 알려져 있습니다.

- 어떤 시점에서 발생한 일이며, 일반적으로 언제 일어났는지를 나타내는 타임스탬프가 포함되어 있습니다.

- 이벤트는 한 번에 하나의 생성자(발행자 또는 송신자)에 의해 생성되고, 그런 다음 여러 소비자(구독자 또는 수신자)에 의해 처리될 수 있습니다.

- 관련된 이벤트는 일반적으로 주제나 스트림으로 그룹화됩니다.

- 파일이나 데이터베이스는 생성자와 소비자를 연결하는 데 충분합니다.

- 생성자는 생성하는 모든 이벤트를 데이터 저장소에 기록하고, 각 소비자는 마지막 실행 이후에 나타난 이벤트를 확인하기 위해 주기적으로 데이터 저장소를 폴링합니다.

- 그러나 계속해서 처리로 이동할 때 폴링은 비용이 많이 듭니다.

- 새로운 이벤트가 나타날 때 소비자에게 알릴 때가 더 나은 것입니다.

- 데이터베이스는 트리거를 제공하지만 제한적입니다.
  - 따라서 이벤트 알림을 전달하는 목적으로 전문 도구가 개발되었습니다.

### 2.1 메시징 시스템

- 생산자에서 소비자로 직접 메시지 전송

  - 발행/구독 모델 내에서 우리는 두 가지 질문을 통해 시스템을 구분할 수 있습니다:

    - 생산자가 메시지를 생성자가 처리할 수 있는 속도보다 빠르게 보내면 어떻게 됩니까? 시스템은 메시지를 삭제하거나 메시지를 대기열에 버퍼링하거나 백프레셔를 적용하여(플로우 제어, 생성자가 더 많은 메시지를 보낼 수 없게 차단함) 처리할 수 있습니다.

    - 노드가 충돌하거나 일시적으로 오프라인 상태인 경우 메시지가 손실됩니까? 내구성을 위해서는 디스크에 쓰거나/또는 복제의 조합이 필요할 수 있습니다.

- 일부 메시징 시스템은 중간 노드 없이 생산자와 소비자 간의 직접 통신을 사용합니다:

      - UDP 멀티캐스트, 낮은 지연 시간이 중요한 경우, 애플리케이션 수준 프로토콜은 손실된 패킷을 복구할 수 있습니다.

      - 중개자 없이 메시지 라이브러리(ZeroMQ와 같은) StatsD와 Brubeck은 메트릭 수집을 위해 신뢰성 없는 UDP 메시징을 사용합니다.

      - 소비자가 네트워크에서 서비스를 노출하는 경우, 생산자는 메시지를 푸시하기 위해 직접 HTTP 또는 RPC 요청을 할 수 있습니다. 이것이 웹훅(웹훅의 아이디어는 한 서비스의 콜백 URL을 다른 서비스에 등록하고 이벤트가 발생할 때마다 해당 URL로 요청을 보내는 것입니다).

- 이러한 직접 메시징 시스템은 메시지 손실 가능성을 인식하도록 응용 프로그램 코드를 요구합니다.

- 그들이 허용할 수 있는 결함은 생성자와 소비자가 지속적으로 온라인이라고 가정하기 때문에 상당히 제한적입니다.

- 소비자가 오프라인 상태인 경우 메시지를 놓칠 수 있습니다.

- 일부 프로토콜은 실패한 메시지 전달을 다시 시도할 수 있게 허용하지만 생성자가 버퍼나 메시지를 잃어버린 경우에는 문제가 발생할 수 있습니다.

### 2.2 메시지 브로커

- 대안으로 메시지 브로커(또는 메시지 큐)를 통해 메시지를 보내는 것이 가능합니다.

- 이는 메시지 스트림을 처리하기 위해 최적화된 데이터베이스와 유사한 것으로, 생성자와 소비자가 클라이언트로 연결되는 서버로 작동합니다.

- 생성자는 메시지를 브로커에 기록하고, 소비자는 브로커에서 메시지를 읽어 받습니다.

- 데이터를 중앙 집중화함으로써 이러한 시스템은 들어오고 가는 클라이언트를 쉽게 처리할 수 있으며 내구성의 문제는 브로커로 옮겨집니다.

- 일부 브로커는 메시지를 메모리에만 유지하며, 다른 브로커는 브로커 충돌 시 메시지가 손실되지 않도록 디스크에 기록합니다.

- 큐잉의 결과로 소비자는 일반적으로 비동기적입니다:

  - 생성자는 메시지를 브로커가 메시지를 버퍼링했다고 확인할 때까지 기다리며, 메시지가 소비자에 의해 처리될 때까지 기다리지 않습니다.

- 일부 브로커는 XA 및 JTA를 사용하여 이중 커밋 프로토콜에 참여할 수 있습니다.

- 이로써 이들은 데이터베이스와 유사하게 되며, 일부 실질적인 차이점을 제외하고는 유사합니다:

  - 대부분의 메시지 브로커는 메시지가 성공적으로 소비자에게 전달되면 메시지를 자동으로 삭제합니다.

  - 이로 인해 장기 저장에는 적합하지 않습니다.

  - 대부분의 메시지 브로커는 작업 집합이 상당히 작다고 가정합니다.

  - 브로커가 많은 메시지를 버퍼링해야 하는 경우 개별 메시지 처리 시간이 더 오래 걸리며 전체 처리량이 저하될 수 있습니다.

  - 메시지 브로커는 종종 일부 패턴과 일치하는 주제의 하위 집합을 구독하는 방법을 지원합니다.
  - 메시지 브로커는 임의의 쿼리를 지원하지 않지만 데이터 변경 시 클라이언트에 알립니다.

- 이것은 JMS 및 AMQP와 같은 표준으로 캡슐화된 메시지 브로커의 전통적인 관점입니다.

  - RabbitMQ, ActiveMQ, HornetQ, Qpid, TIBCO Enterprise Message Service, IBM MQ, Azure Service Bus 및 Google Cloud Pub/Sub에서 구현됩니다.

- 동일한 주제에서 여러 소비자가 메시지를 읽을 때 주로 사용되는 두 가지 주요 패턴은 다음과 같습니다:

  - 로드 밸런싱: 각 메시지는 한 소비자에게 전달됩니다. 브로커는 메시지를 임의로 소비자에게 할당할 수 있습니다.

  - 팬아웃: 각 메시지는 모든 소비자에게 전달됩니다.

- 메시지가 손실되지 않도록 하기 위해 메시지 브로커는 확인을 사용합니다.

- 클라이언트는 메시지 처리가 완료되었을 때 브로커에 명시적으로 알려야 하므로 브로커는 메시지를 큐에서 제거할 수 있습니다.

- 로드 밸런싱과 재전송을 결합하면 메시지가 불가피하게 재정렬되는 결과가 발생할 수 있습니다.

- 이러한 문제를 피하려면 각 소비자 당 별도의 큐를 사용할 수 있습니다(로드 밸런싱 기능 사용 안 함).

## 3. 파티션된 로그

- 배치 프로세스의 주요 특징 중 하나는 입력을 손상시키지 않고 여러 번 실행할 수 있다는 것입니다.

- 이것은 AMQP/JMS 스타일 메시징과는 다릅니다.

- 메시지 수신은 확인이 브로커에서 메시지를 삭제하도록 하는 경우에는 파괴적입니다.

- 메시징 시스템에 새로운 소비자를 추가하면 이전 메시지는 이미 사라갔으며 복구할 수 없습니다.

- 우리는 데이터베이스의 내구성 저장 접근 방식과 메시징의 저지연 알림 기능을 결합할 수 있으며 이것이 로그 기반 메시지 브로커 아이디어입니다.

- 로그는 디스크의 레코드에 대한 단순한 추가 전용 시퀀스입니다.

- 동일한 구조는 메시지 브로커를 구현하는 데 사용될 수 있습니다.

- 생성자는 메시지를 로그 끝에 추가하여 메시지를 보냅니다.

- 소비자는 로그를 순차적으로 읽어 메시지를 수신합니다.

- 소비자가 로그의 끝에 도달하면 새로운 메시지가 추가되었다는 알림을 기다립니다.

- 단일 디스크가 제공할 수 있는 처리량을 늘리기 위해 로그를 파티션할 수 있습니다.

- 다른 파티션은 다른 기계에서 호스팅될 수 있습니다. 그런 다음 주제는 모두 동일한 유형의 메시지를 전달하는 파티션 그룹으로 정의될 수 있습니다.

- 각 파티션 내에서 브로커는 모든 메시지에 대해 단조로운 증가 시퀀스 번호 또는 오프셋을 할당합니다.

- Apache Kafka, Amazon Kinesis Streams 및 Twitter의 DistributedLog은 이와 같이 작동하는 로그 기반 메시지 브로커입니다.

- 로그 기반 접근은 팬-아웃 메시징을 쉽게 지원하며 여러 소비자는 서로에게 영향을주지 않고 로그를 독립적으로 읽을 수 있습니다.

- 메시지를 읽는 것은 메시지를 로그에서 삭제하지 않습니다.

- 로드 밸런싱을 달성하기 위해 브로커는 소비자 그룹의 노드에 전체 파티션을 할당할 수 있습니다.

- 그런 다음 각 클라이언트는 할당된 파티션의 모든 메시지를 소비합니다. 이 접근 방식에는 몇 가지 단점이 있습니다.

  - 주제를 소비하는 노드 수는 해당 주제의 로그 파티션 수와 동일할 수 있습니다.

  - 단일 메시지가 처리가 느릴 경우 해당 파티션의 후속 메시지 처리가 지연됩니다.

- 메시지 처리가 비용이 많이 들 수 있고 메시지별로 처리를 병렬화하고 메시지 순서가 그다지 중요하지 않은 경우 JMS/AMQP 스타일 메시지 브로커가 선호됩니다.

- 메시지 처리량이 높고 각 메시지 처리가 빠르며 메시지 순서가 중요한 경우 로그 기반 접근 방식이 아주 잘 작동합니다.

- 메시지가 처리된 정도를 쉽게 확인할 수 있습니다.

- 현재 소비자 오프셋보다 낮은 오프셋을 가진 모든 메시지는 이미 처리되었으며 더 큰 오프셋을 가진 모든 메시지는 아직 보지 못한 것입니다.

- 오프셋은 단일 리더 데이터베이스 복제에서 일반적으로 찾을 수 있는 로그 시퀀스 번호와 매우 유사합니다. 메시지 브로커는 리더 데이터베이스처럼 작동하고 소비자는 팔로워처럼 작동합니다.

- 소비자 노드가 실패하면 소비자 그룹의 다른 노드가 마지막 기록된 오프셋에서 메시지를 소비하기 시작합니다.

- 소비자가 후속 메시지를 처리했지만 아직 오프셋을 기록하지 않았다면 다시 시작할 때 이러한 메시지가 두 번 처리됩니다.

- 로그에 항상 추가하기만 한다면 언젠가는 디스크 공간이 부족해집니다.

- 때때로 오래된 세그먼트는 삭제되거나 아카이브로 이동됩니다.

- 느린 소비자가 메시지 처리 속도를 따라잡지 못하고 너무 뒤떨어진 경우, 그리고 그 소비자 오프셋이 삭제된 세그먼트를 가리키게 되면 일부 메시지를 놓칠 수 있습니다.

- 로그의 처리량은 대부분 일정합니다.

  - 왜냐하면 모든 메시지가 어차피 디스크에 기록되기 때문입니다.

- 이는 메모리에 메시지를 기본적으로 유지하고 큐가 너무 커지면 디스크에만 쓰기 시작하는 메시징 시스템과 대조적입니다.

- 시스템은 큐가 짧을 때 빠르며 큐가 디스크에 쓰기 시작하면 훨씬 느려지며 처리량은 보유한 이력의 양에 따라 달라집니다.

- 소비자가 생성자에 따라 따라가기 어려운 경우, 소비자는 메시지를 삭제하거나 버퍼링하거나 백프레셔를 적용할 수 있습니다.

- 소비자가 로그의 머리 부분에서 얼마나 뒤떨어져 있는지 모니터링하고 크게 뒤떨어진 경우 경고를 발생시킬 수 있습니다.

- 소비자가 너무 뒤떨어져 메시지를 놓치기 시작하면 영향을 받는 것은 그 소비자 뿐입니다.

- AMQP와 JMS 스타일 메시지 브로커에서 메시지를 처리하고 확인하는 것은 메시지를 브로커에서 삭제하기 때문에 파괴적인 작업입니다.

- 로그 기반 메시지 브로커에서 메시지를 소비하는 것은 파일에서 읽는 것과 더 유사합니다.

- 오프셋은 소비자가 제어하는 대로 조작할 수 있으므로 필요한 경우 오래된 메시지를 다시 재생하는 등의 작업을 쉽게 수행할 수 있습니다.

## 4. 데이터베이스와 스트림

- 복제 로그는 트랜잭션을 처리하는 동안 리더가 생성하는 데이터베이스 쓰기 이벤트의 스트림입니다.

- 팔로워는 이러한 쓰기 스트림을 자체 데이터베이스 사본에 적용하여 동일한 데이터의 정확한 사본을 얻습니다.

- 정기적인 전체 데이터베이스 덤프가 너무 느리다면 대안 중 하나로 듀얼 라이트(이중 쓰기)가 때로 사용됩니다. 예를 들어, 데이터베이스에 쓰기, 검색 인덱스 업데이트, 캐시 무효화 순서로 진행됩니다.

- 듀얼 라이트에는 일부 심각한 문제가 있으며 그 중 하나는 경합 조건(race conditions)입니다. 동시에 쓰기 작업이 있는 경우 하나의 값이 다른 값을 무음으로 덮어쓸 수 있습니다.

- 두 개의 시스템 중 하나가 성공하고 다른 하나가 실패할 경우 두 시스템이 불일치 상태에 빠질 수 있습니다.

- 대부분의 데이터베이스 복제 로그의 문제는 내부 구현 세부 사항으로 간주되어 공개 API가 아니라는 것입니다.

- 최근에는 데이터베이스에 기록된 모든 데이터 변경 사항을 관찰하고 다른 시스템으로 복제할 수 있는 형식으로 추출하는 변경 데이터 캡처(CDC)에 대한 관심이 증가하고 있습니다.

- 예를 들어, 데이터베이스의 변경 내용을 캡처하고 동일한 변경 내용을 검색 인덱스에 지속적으로 적용할 수 있습니다.

- 로그 소비자를 파생 데이터 시스템으로 볼 수 있으며 검색 인덱스와 데이터 웨어하우스에 저장된 데이터는 또 다른 뷰에 불과합니다. 변경 데이터 캡처는 원본 시스템에 수행된 모든 변경 사항이 파생 데이터 시스템에도 반영되도록 하는 메커니즘입니다.

- 변경 데이터 캡처는 하나의 데이터베이스를 리더로 만들고 다른 데이터베이스를 팔로워로 변환합니다.

- 데이터베이스 트리거를 사용하여 변경 데이터 캡처를 구현할 수 있지만 취약하고 상당한 성능 오버헤드가 있을 수 있습니다. 복제 로그를 구문 분석하는 것이 더 견고한 접근 방식일 수 있습니다.

- LinkedIn의 Databus, Facebook의 Wormhole 및 Yahoo!의 Sherpa는 이 아이디어를 대규모로 활용합니다. Bottled Watter는 PostgreSQL을 위한 CDC를 구현하며 Write-Ahead Log를 디코딩합니다. Maxwell와 Debezium은 MySQL을 위한 유사한 기능을 이용하기 위해 binlog를 구문 분석합니다. Mongoriver는 MongoDB oplog를 읽고, GoldenGate는 Oracle을 위한 유사한 기능을 제공합니다.

- 모든 변경 사항을 영구적으로 보관하려면 너무 많은 디스크 공간이 필요하며 다시 재생하는 데 시간이 오래 걸릴 수 있으므로 로그를 자르는 것이 필요합니다.

- 데이터베이스의 일관된 스냅샷에서 시작해야 하며 이는 변경 로그의 알려진 위치 또는 오프셋과 일치해야 합니다.

- 저장 엔진은 동일한 키를 가진 로그 레코드를 주기적으로 찾아서 중복을 제거하고 각 키에 대해 가장 최근의 업데이트만 유지합니다.

- 특수한 널 값(툼스톤)을 가진 업데이트는 키가 삭제되었음을 나타냅니다.

- 동일한 아이디어는 로그 기반 메시지 브로커 및 변경 데이터 캡처 컨텍스트에서도 작동합니다.

- RethinkDB는 쿼리가 알림을 구독하도록 허용하며, Firebase와 CouchDB는 변경 피드를 기반으로 데이터 동기화를 제공합니다.

- Kafka Connect는 다양한 데이터베이스 시스템을 위한 변경 데이터 캡처 도구를 Kafka와 통합합니다.

### 4.1 이벤트 소싱(Event Sourcing)

- 여기에서 논의한 아이디어와 이벤트 소싱(Event Sourcing) 사이에는 일부 유사점이 있습니다.

- 변경 데이터 캡처와 유사하게 이벤트 소싱은 응용 프로그램 상태의 모든 변경 내용을 변경 이벤트의 로그로 저장하는 것을 포함합니다. 이벤트 소싱은 추상화 수준에서 다른 방식으로 이 아이디어를 적용합니다.

- 이벤트 소싱은 시간이 지남에 따라 응용 프로그램을 발전시키는 것을 더 쉽게 만들어주며, 왜 어떤 일이 발생했는지 이해하기 쉽게 만들어 디버깅에 도움을 주며, 응용 프로그램 버그에 대비합니다.

- Event Store와 같은 전문 데이터베이스는 이벤트 소싱을 사용하는 응용 프로그램을 지원하기 위해 개발되었습니다.

- 이벤트 소싱을 사용하는 응용 프로그램은 이벤트 로그를 가져와 사용자에게 표시할 수 있는 응용 프로그램 상태로 변환해야 합니다.

- 이벤트 로그를 다시 재생하면 시스템의 현재 상태를 재구성할 수 있습니다.

- 이벤트 소싱을 사용하는 응용 프로그램은 일반적으로 스냅샷을 저장하는 메커니즘을 가지고 있습니다.

- 이벤트 소싱 철학은 이벤트와 명령(command)을 구분하는 것에 주의를 기울입니다. 사용자의 요청이 처음 도착하면 초기에는 명령입니다. 여전히 실패할 수 있습니다(일부 무결성 조건이 위배될 수 있음). 검증이 성공하면 이벤트로 변환되며, 이벤트는 내구성을 가지며 불변입니다.

- 이벤트 스트림의 소비자는 이벤트를 거부할 수 없습니다. 명령의 유효성 검사는 이벤트가 되기 전에 동기적으로 수행되어야 합니다. 예를 들어, 명령을 검증하고 이벤트를 게시하는 원자적인 트랜잭션을 사용하여 동기적으로 수행될 수 있습니다.

- 또는 사용자 요청을 좌석 서비스에 대한 예약으로 나눌 수 있습니다. 먼저 임시 예약을 만들고 예약이 검증된 후 별도의 확인 이벤트를 생성합니다. 이 분할을 통해 검증이 비동기 프로세스에서 수행될 수 있습니다.

- 상태 변경이 발생할 때 해당 상태는 시간에 따라 변화한 이벤트의 결과입니다.

- 가변 상태와 불변한 이벤트의 로그는 서로 모순되지 않습니다.

- 예를 들어, 재무 회계는 이벤트가 기록된 불변의 장부로 기록됩니다. 이것은 돈, 상품 또는 서비스의 교환에 대한 변경 사항을 설명하는 이벤트의 로그입니다. 손익 계산서나 재무 상태표는 장부에서 그 값을 더하여 얻습니다.

- 잘못된 트랜잭션을 작성한 경우, 회계사는 잘못된 트랜잭션을 지우거나 수정하는 대신 잘못된 트랜잭션을 보상하는 다른 트랜잭션을 추가합니다.

- 버그 있는 코드가 데이터베이스에 잘못된 데이터를 작성하면 코드가 데이터를 파괴적으로 덮어쓸 수 있으므로 복구가 훨씬 어려워집니다.

- 불변한 이벤트는 현재 상태뿐만 아니라 현재 상태 외의 정보도 포함합니다. 일반적인 데이터베이스에 카트를 저장하면 항목을 삭제하면 해당 이벤트를 효과적으로 잃게 됩니다.

- 같은 이벤트 로그에서 뷰를 파생할 수 있으며, Druid는 Kafka에서 직접 가져와서 사용하며, Pistachio는 커밋 로그로 Kafka를 사용하는 분산 키-값 저장소이며, Kafka Connect sink는 Kafka에서 다양한 다른 데이터베이스와 인덱스로 데이터를 내보낼 수 있습니다.

- 데이터를 저장하는 것은 일반적으로 쿼리와 액세스 방법에 대해 걱정할 필요가 없는 경우에는 상당히 간단합니다. 데이터가 쓰여진 형식과 읽히는 형식을 분리함으로써 많은 유연성을 얻을 수 있으며, 이 아이디어는 명령-쿼리 책임 분리(CQRS, Command Query Responsibility Segregation)로 알려져 있습니다.

- 데이터를 저장하는 것은 일반적으로 쿼리 및 액세스 방법에 대해 걱정할 필요가 없는 경우에는 상당히 간단합니다. 데이터가 작성된 형식과 읽히는 형식을 분리함으로써 많은 유연성을 얻을 수 있으며, 이러한 아이디어는 명령-쿼리 책임 분리(CQRS, Command Query Responsibility Segregation)로 알려져 있습니다.

- 데이터는 쿼리될 형식과 동일한 형식으로 작성되어야 한다는 오해가 있습니다.

- 이벤트 소싱과 변경 데이터 캡처의 가장 큰 단점은 이벤트 로그의 소비자가 일반적으로 비동기적이라는 것입니다. 사용자가 로그에 쓰기를 수행한 다음 로그에서 파생된 뷰에서 읽으면 쓰기가 아직 반영되지 않은 것을 발견할 수 있습니다.

- 불변한 이벤트 히스토리에 대한 제한은 데이터 세트의 변동량에 따라 달라집니다. 일부 워크로드는 주로 데이터를 추가하고 드물게 업데이트하거나 삭제하므로 불변한 히스토리를 만드는 것이 쉽습니다. 다른 워크로드는 상대적으로 작은 데이터 세트에서 높은 업데이트 및 삭제 비율을 가지므로 불변한 히스토리는 단편화, 성능 조각화 및 가비지 수집 때문에 문제가 될 수 있습니다.

- 데이터를 관리상의 이유로 삭제해야 하는 상황이 있을 수도 있습니다.

- 때로는 히스토리를 다시 작성하고 싶을 수 있으며, Datomic은 이 기능을 "excision(제거)"이라고 부릅니다.

## 5. 스트림 처리

- 스트림을 얻은 후에 할 수 있는 작업은 다음과 같습니다.

  - 이벤트의 데이터를 데이터베이스, 캐시, 검색 인덱스 또는 유사한 저장 시스템에 기록하여 다른 클라이언트가 쿼리할 수 있도록 합니다.

  - 이벤트를 어떤 방식으로든 사용자에게 푸시할 수 있습니다. 예를 들어 이메일 알림 또는 푸시 알림을 보내거나 실시간 대시보드로 이벤트를 푸시할 수 있습니다.

  - 하나 이상의 입력 스트림을 처리하여 하나 이상의 출력 스트림을 생성할 수 있습니다.

- 입력 스트림을 처리하여 파생 스트림을 생성하는 것이 연산자 작업이 수행하는 작업입니다. 배치 작업과 가장 중요한 차이점은 스트림이 결코 끝나지 않는다는 것입니다.

- 복잡한 이벤트 처리(CEP)는 이벤트 스트림을 분석하는 접근 방식으로, 이벤트 스트림에서 특정 이벤트 패턴을 검색하는 규칙을 지정할 수 있습니다. 일치 항목을 찾으면 엔진이 복잡한 이벤트를 발생시킵니다. 쿼리는 장기 저장되며 입력 스트림에서 이벤트 패턴과 일치하는 쿼리를 찾아 계속 이동합니다.

- EP의 구현체로는 Esper, IBM InfoSphere Streams, Apama, TIBCO StreamBase 및 SQLstream 등이 있습니다.

- CEP와 스트림 분석 간의 경계는 흐릿할 수 있으며, 스트림 분석은 주로 특정 이벤트 시퀀스를 찾는 대신 집계 및 통계 지표에 더 관심이 있습니다.

- 분석을 고려한 프레임워크로는 Apache Storm, Spark Streaming, Flink, Concord, Samza 및 Kafka Streams가 있으며, 호스팅된 서비스로는 Google Cloud Dataflow 및 Azure Stream Analytics가 있습니다.

- 때로는 스트림을 통해 지속적으로 개별 이벤트를 검색해야 할 필요가 있습니다. 예를 들어 스트림 상에서의 풀 텍스트 검색 쿼리 등이 있습니다.

- 메시지 전달 시스템도 메시지와 이벤트를 기반으로 하지만 일반적으로 스트림 프로세서로 생각하지는 않습니다.

- RPC와 스트림 처리 사이에는 약간의 중첩 영역이 있을 수 있습니다. Apache Storm에는 분산 RPC라는 기능이 있습니다.

- 배치 프로세스에서 프로세스 실행 시간은 실제 이벤트 발생 시간과 아무런 관련이 없습니다.

- 많은 스트림 처리 프레임워크는 처리 시간을 결정하기 위해 처리 머신의 로컬 시스템 시계(처리 시간)를 사용합니다. 이는 중요한 처리 지연이 발생하는 경우 문제가 발생합니다.

- 이벤트 시간과 처리 시간을 혼동하면 나쁜 데이터가 발생합니다. 처리 시간은 스트림 프로세서가 이벤트를 큐에 넣거나 다시 시작하는 경우와 같이 신뢰할 수 없을 수 있습니다. 이벤트의 원래 시간을 고려하여 속도를 계산하는 것이 더 좋습니다.

- 모든 이벤트를 받았다는 것을 확신할 수는 없습니다.

- 일정 시간 동안 새 이벤트를 관찰하지 않은 후 윈도우를 준비 상태로 선언하고 타임 아웃할 수 있지만, 네트워크 중단으로 인해 일부 이벤트가 지연될 수도 있습니다. 윈도우가 이미 완료되었음에도 불구하고 이러한 지연된 이벤트를 처리할 수 있어야 합니다.

- 다음과 같은 방법으로 이러한 지연 이벤트를 처리할 수 있습니다.

  - 이상한 이벤트를 무시하고 놓친 이벤트 수를 지표로 추적합니다.

  - 수정 사항을 게시하고, 이상한 이벤트를 포함한 윈도우의 업데이트 값을 게시합니다. 또한 이전 출력을 철회해야 할 수도 있습니다.

- 장치 시계의 부정확한 값을 조정하기 위한 한 가지 방법은 다음과 같이 세 가지 타임스탬프를 기록하는 것입니다.

  - 이벤트가 장치 시계에 따라 발생한 시간

  - 이벤트가 서버로 전송된 시간(장치 시계에 따라)

  - 이벤트가 서버에서 수신된 시간(서버 시계에 따라)

- 장치 시계와 서버 시계 간의 오프셋을 추정한 다음 해당 오프셋을 이벤트 타임스탬프에 적용하여 실제로 이벤트가 발생한 시간을 추정할 수 있습니다.

- 일반적으로 사용되는 여러 윈도우 유형이 있습니다:

  - 텀블링 윈도우: 고정된 길이를 가지며, 예를 들어 1분 텀블링 윈도우는 10:03:00부터 10:03:59까지의 모든 이벤트를 하나의 윈도우에 그룹화합니다. 다음 윈도우는 10:04:00에서 10:04:59까지입니다.

  - 합침 윈도우: 고정된 길이를 가지지만 일부 스무딩을 제공하기 위해 윈도우가 중첩될 수 있습니다. 예를 들어 1분 간격의 5분 합침 윈도우는 10:03:00부터 10:07:59까지의 이벤트를 포함할 것이며, 다음 윈도우는 10:04:00에서 10:08:59까지를 포함할 것입니다.

  - 슬라이딩 윈도우: 서로 일정 시간 간격으로 발생하는 이벤트를 포함합니다. 예를 들어 5분 슬라이딩 윈도우는 10:03:39와 10:08:12를 포함할 것이며 이는 4분 미만의 간격으로 발생하기 때문입니다.

  - 세션 윈도우: 고정된 기간이 없으며, 사용자별로 모든 이벤트를 포함하며 사용자가 일정 시간(30분) 동안 비활성 상태가되면 윈도우가 종료됩니다. 웹사이트 분석에서 일반적입니다.

- 스트림에 언제든지 새로운 이벤트가 나타날 수 있기 때문에 스트림에서 조인을 수행하는 것은 어려운 작업입니다.

### 5.1 스트림-스트림 조인

- 검색된 URL의 최근 트렌드를 감지하려고 합니다. 쿼리를 포함한 이벤트를 기록합니다. 누군가 검색 결과 중 하나를 클릭하면 클릭을 기록하는 다른 이벤트를 기록합니다. 검색 작업 및 클릭 작업의 이벤트를 모으어야 합니다.

- 이 유형의 조인을 위해 스트림 프로세서는 상태를 유지해야 합니다. 지난 1시간 동안 발생한 모든 이벤트를 세션 ID로 색인화합니다. 검색 이벤트나 클릭 이벤트가 발생하면 해당 인덱스에 추가되고, 스트림 프로세서는 다른 인덱스도 확인하여 동일한 세션 ID의 다른 이벤트가 이미 도착했는지 확인합니다. 일치하는 이벤트가 있는 경우 검색 결과가 클릭되었다는 이벤트를 발생시킵니다.

### 5.2 스트림-테이블 조인

- 때로는 활동 이벤트를 데이터베이스에서 가져온 정보로 보강하는 것으로도 알려집니다.

- 두 개의 데이터 세트를 상상해보십시오. 사용자 활동 이벤트 세트와 사용자 프로필 데이터베이스가 있습니다. 활동 이벤트에는 사용자 ID가 포함되어 있으며, 결과 스트림은 사용자 ID를 기반으로 프로필 정보를 보강해야 합니다.

- 스트림 프로세스는 한 번에 하나의 활동 이벤트를 살펴보고 이벤트의 사용자 ID를 데이터베이스에서 조회한 다음 활동 이벤트에 프로필 정보를 추가해야 합니다. 데이터베이스 조회는 원격 데이터베이스를 쿼리함으로써 구현할 수 있지만, 이는 느리고 데이터베이스를 과도하게 사용할 수 있습니다.

- 다른 접근 방식은 데이터베이스의 사본을 스트림 프로세서에로드하여 네트워크 왕복 없이 로컬로 조회할 수 있도록 하는 것입니다. 스트림 프로세서의 로컬 데이터베이스 사본은 최신 상태로 유지되어야 합니다. 이는 변경 데이터 캡처를 사용하여 해결할 수 있습니다.

### 5.3 테이블-테이블 조인

- 스트림 프로세스는 각 사용자의 팔로워 집합을 포함하는 데이터베이스를 유지하여 새로운 트윗이 도착할 때 어떤 타임라인을 업데이트해야 하는지 알아야 합니다.

### 5.4 시간 의존성 조인

- 앞서 설명한 세 가지 유형의 조인은 스트림 프로세서가 일부 상태를 유지해야 한다는 것을 의미합니다.

- 상태가 시간에 따라 변경되고 특정 시점의 상태와 조인하는 경우 어떤 시점의 시간을 사용해야 할까요?

- 스트림 간 이벤트의 순서가 결정되지 않으면 조인이 비결정적이 됩니다.

- 이 문제를 천천히 변하는 차원(Slowly Changing Dimension, SCD)이라고 합니다. 종종 조인된 레코드의 특정 버전에 대한 고유 식별자를 사용하여 이 문제를 해결합니다. 예를 들어, 세금율이 변경될 때마다 새로운 식별자가 부여되고 판매 시점의 세율 식별자가 청구서에 포함될 경우 시스템을 결정적으로 만들 수 있습니다. 그러나 결과적으로 로그 캡처가 불가능해집니다.

### 5.5 내결함성 (Fault Tolerance)

- 일괄 처리 프레임워크는 오류를 상당히 쉽게 허용할 수 있습니다. 맵리듀스 작업에서 작업이 실패하면 다른 기계에서 다시 시작할 수 있으며 입력 파일은 불변하며 출력은 별도의 파일로 작성됩니다.

- 작업을 다시 시작하더라도 레코드가 여러 번 처리될 수 있지만 출력에서의 가시적인 효과는 한 번만 처리된 것처럼 보입니다(정확히 한 번만 처리되는 의미 또는 효과적으로 한 번).

- 스트림 처리에서 작업이 완료될 때까지 기다리고 출력을 보이기 전에는 옵션이 아닙니다. 스트림은 무한하기 때문입니다.

- 스트림을 작은 블록으로 나누고 각 블록을 미니배치 프로세스처럼 처리하는 것(마이크로 배칭)이 한 가지 해결책입니다. 이 기술은 Spark Streaming에서 사용되며 배치 크기는 일반적으로 1초 정도입니다.

- Apache Flint에서 사용되는 대체 방법은 주기적으로 상태의 롤링 체크포인트를 생성하고 내구성 있는 저장소에 기록하는 것입니다. 스트림 연산자가 충돌하면 가장 최근의 체크포인트에서 다시 시작할 수 있습니다.

- 마이크로 배칭 및 체크포인팅 접근법은 일괄 처리와 동일한 정확히 한 번만 처리하는 의미를 제공합니다. 그러나 출력이 스트림 프로세서를 벗어나자마자 프레임워크는 실패한 배치의 출력을 더 이상 삭제할 수 없습니다.

- 정확히 한 번만 처리하는 것처럼 보이도록 하려면 작업이 원자적으로 발생하거나 전혀 발생하지 않아야 합니다. 여러 작업이 동기화되어야 하며 서로 동기화되지 않아야 합니다. 분산 트랜잭션 및 이상적으로 두 단계 커밋을 사용할 수 있습니다.

- 이 접근 방식은 Google Cloud Dataflow 및 VoltDB에서 사용되며 Apache Kafka에 유사한 기능을 추가하는 계획이 있습니다.

- 우리의 목표는 실패한 작업의 부분 출력을 버려서 두 번 효과를 미치지 않고 안전하게 폐기하는 것입니다. 분산 트랜잭션은이 목표를 달성하는 한 가지 방법이지만 아이덴포턴스에 의존하는 다른 방법도 있습니다.

- 아이덴포턴트 작업은 여러 번 수행하더라도 한 번만 수행한 것과 동일한 효과가 있는 작업입니다.

- 작업이 원래 아이덴포턴트가 아니더라도 약간의 추가 메타데이터를 사용하여 아이덴포턴트로 만들 수 있습니다. 업데이트가 이미 적용되었는지 여부를 알 수 있습니다.

- 아이덴포턴트 작업은 소규모 오버헤드만으로 정확히 한 번만 처리하는 효과적인 방법일 수 있습니다.

- 상태를 필요로 하는 모든 스트림 프로세스는 실패 후에 상태를 복구할 수 있어야 합니다.

- 상태를 원격 데이터 저장소에 유지하고 복제하는 옵션이 있지만 이 방법은 느릴 수 있습니다.

- 대안으로 상태를 스트림 프로세서에 로컬로 유지하고 주기적으로 복제할 수 있습니다.

- Flink는 주기적으로 스냅샷을 캡처하고 HDFS와 같은 내구성 있는 저장소에 기록합니다. Samza와 Kafka Streams는 상태 변경을 로그 압축을 사용하는 전용 Kafka 주제로 보내 상태를 복제합니다. VoltDB는 여러 노드에서 각 입력 메시지를 중복 처리하여 상태를 복제합니다.
