# chapter 11. 스트림 처리

- 배치 프로세싱과 다르게 이벤트 발생시점에 그때 끄때 처리하는 것. 

## 이벤트 스트림 전송
- producer(publisher, sender): event writer
- consumer(subscriber, recipient): event reader
- topic: event를 묶는 집합

### 메시징 시스템
pub/sub 모델에서 여러 다양한 접근법들이 있는데, 아래 2가지 질문이 시스템을 구별하는데 많은 도움이 된다.
1. producer가 consumer의 처리속도보다 더 빨리 event를 전송한다면?
   - 메시지 버리기
   - 큐에 메시지 버퍼링
   - producer가 메시지 더이상 못 보내도록 막음(backpressure)
2. 노드가 죽거나 일시적으로 오프라인이 된다면 어떻게 될까? 손실되는 메시지가 있을까?
   - 디스크에 기록하거나 복제본을 만든다 => 비용이 든다. 
   - 메시지를 잃어도 괜찮다면 같은 하드웨어에서 처리할 수도 있다.

#### 메시징 시스템 종류
- 생산자에서 소비자로 메시지를 직접 전달하기
  - ex) UDP multicast, ZeroMQ, StatsD, WebHook 등
  - 메시지가 유실될 수 있는 가능성을 고려해서 애플리케이션을 구성해야 한다.
  - consumer가 오프라인이 되면 메시지 유실될 수 있다.
  - producer가 죽으면, re-try하려고 했던 메시지가 유실될 수 있다.
- 메시지 브로커
  - 메시지 스트림을 처리하는데 최적화된 일종의 데이터베이스
  - 브로커에서 데이터를 관리하기 떄문에, 클라이언트 상태 변경에도 대처 가능
  - 브로커 자체에서 내결함성을 갖출 수 있다.
  - ***비동기***로 동작

#### 메시지 브로커와 데이터베이스의 비교
- 데이터베이스는 삭제되기 전까지 데이터 보관. 메시지 브로커는 consumer에게로 데이터 전달되면 자동으로 삭제
  - retention 설정이 가능할텐데??
- 작업 직합이 상당히 작다고 가정. => 큐 크기가 작다.
- 데이터베이스는 보조 색인을 지원하고 데이터 검색을 위한 다양한 방법을 지원. 메시지 브로커는 특정 패턴과 부합하는 토픽의 부분 집합을 구독하는 방식 
- 데이터베이스에 질의 결과는 일반적으로 질의 시점의 데이터 스냅숏을 기준. 메시지 브로커는 임의 질의를 지원하지 않지만 데이터가 변하면 클라이언트에게 알려준다.


#### 복수 소비자
같은 토픽에서 메시지를 읽을 떄 사용하는 주요 패턴 두 가지
- load balancing
  - 각 메시지는 각 소비자 중 하나로 전달
  - JMS에서는 shared subscription이라 함.
- fan-out
  - 각 메시지는 모든 소비자에게 전달

#### 확인 응답과 재전송
- consumer는 언제든 장애가 발생할 수 있다. 
브로커는 consumer에게 메시지를 전달했지만, consumer가 처리하지 못했을 수 있다. 
이러한 장애로 인한 메시지 유실을 방지 하기 위해 메시지 브로커는 ***확인 응답(ack)*** 을 사용한다.
- ack를 받지 못한 경우에 다른 consumer에게 재전송
- load-balancing 방법에서 이런 re-try가 메시지 순서가 변경 될수 있다. => load-balancing을 안하면 피할 수 있다.
  - 메시지 인과성은 중요한 문제기 떄문에 후반부에 다시 다룰 예정

### 파티셔닝된 로그
기본적으로 메시지 브로커는 데이터를 영구적으로 저장하지 않는다. 이전 메시지를 다시 가져올 수도 없다. 

데이터베이스의 지속성 있는 저장방법과 메시징 시스템의 지연시간이 짧은 알림 기능을 조합할수는 없을까? => ***log-based message broker*** 

#### 로그를 사용한 메시지 저장소
- 지속성 있도록 저장하기 위해서 디스크에 로그처럼 데이터를 넣을 수 있다.
- 처리량을 높이기 위해서 파티셔닝을 할 수 있다.
- 파티션 마다 모든 메시지에 offset이라는 단조 증가하는 순번을 부여.

#### 로그 방식과 전통적인 메시징 방식의 비교
- 로그 기반 접근법은
  - fan-out을 제공
  - consumer group의 최대 크기 = partition 수
  - 특정 메시지 처리가 느리면 특정 파티션의 후속 메시지 처리가 느려진다.
- 메시지를 처리하는 비용이 비싸고 메시지 단위로 병렬화 처리하고 싶고, 메시지 순서가 중요하지 않다면 JMS/AMQP 방식의 메시지 브로커가 적합
- 처리량이 많고 메시지를 처리하는 속도가 빠르지만 메시지 순서가 중요하면 로그기반 접근법이 적합

#### consumer offset
- offset은 순차적이기 떄문에 매번 offset을 저장할 필요가 없어서 처리량을 올리기 위해서 주기적으로 offset을 기록
- consumer 장애 발생시, consumer group 내 다른 consumer에서 해당 파티션의 마지막 commit된 offset을 가져와서 처리

#### 디스크 공간 사용
- 로그가 계속 추가되면 결국 디스크 문제가 발생할 수 있다.
- 로그는 크기가 제한된 버퍼로 구현하고 버퍼가 가득차면 오래된 메시지 순서대로 버린다.(circular buffer, ring buffer)

#### 소비자가 생산자를 따라갈 수 없을 때
위에서 3가지 방법으로 분류하였음
- 메시지 버리기
- 버퍼링
- backpressure
로그 기반 접근법은 이 방식으로 분류하자면 대용량이지만 고정 크기의 버퍼를 사용하는 버퍼링 형태

#### 오래된 메시지 재생
- 오래된 메시지를 재처리하기 위해 offset만 변경하면 된다.

## 데이터베이스와 스트림
이종 데이터 시스템에서 발생하는 문제 한가지를 살펴보고, 이벤트 스트림의 아이디어를 데이터베이스에 적용해 이 문제를 해결하는 방법을 찾는다.

### 시스템 동기화 유지하기
모든 요구사항을 만족하는 단일 시스템은 없다. 

그래서 여러 시스템(데이터웨어하우스, 검색엔진 등)을 이용하게 되는데, 여러 시스템으로 데이터를 복제하기 위한 방법으로 전체 dump를 할 수가 있다. 

But, 전체 덤프는 너무 느리다. 이걸 해결하기 위해서 dual-write를 생각해볼 수 있다.

But, dual-write에는 몇가지 심각한 문제가 있다.
- 타이밍 불일치로 인한 data in-sync
- 한쪽은 성공, 한쪽은 실패 => 2PC 적용할수 있지만 비용이 크다.

single-leader 처럼 작동하고, 다른 쪽은 replica처럼 할수 없을까?

### 변경 데이터 캡처(Change Data Caputre, CDC)
- 데이터베이스의 변경 사항을 캡쳐해서 스트림으로 제공.

#### CDC의 구현
- 트리거 기반: 고장나기 쉽고 성능 오버헤드가 크다.
- 복제 로그를 파싱하는 방식: 스키마 변경 대응 등을 해결해야 할 문제가 있지만 트리거 방식보다 견고하다.
  - 보통 이 방법을 선호하고, 여러 tool들이 있음. ex) debezium

#### 초기 스냅숏
- 복제 로그에 모든 변경 로그가 없으면, 데이터 베이스 전체 상태를 다 가져오기 위해서 스냅숏을 사용해야 한다.
- 스냅숏 기능을 제공하는 tool도 있고, 수작업으로 해야하는 tool도 있다.
  - debezium의 경우에는 snapshot 기능을 제공.

#### 로그 컴팩션
로그 양이 많기 때문에, 새로운 파생 시스템을 추가할때마다 스냅숏을 만들어야 한다. 
 
이러면 데이터 사이즈가 너무 커지기 때문에 로그 컴팩션(log compaction)으로 이 문제를 해결한다.

CDC 시스템에서 모든 변경에 primary key를 포함하게 하고, 키의 모든 갱신이 해당 key의 이전 값을 교체한다면 특정 키에 대한 최신 값만 유지한다.

그러면, 다시 스냅숏하지않고, offset 0부터 가지고 오면 된다.

#### 변경 스트림용 API 지원
- 최근 데이터베이스들은 기능 개선이나 리버스 엔지니어링을 통해 CDC 지원을 하기보다 점진적으로 변경 스트림을 기본 인터페이스로 지원하기 시작.
  - ex) RethinkDB, FireBase, CouchDB 등
- VoltDB는 스트림 형태로 데이터베이스에서 데이터를 지속적으로 내보내는 트랜잭션을 제공
- Kafka Connect: 카프카를 광범위한 데이터 시스템용 변경 데이터 캡처 도구로 활용하는 tool

### 이벤트 소싱
- DDD(Domain-Driven Design) 커뮤니티에서 개발한 기법
- 애플리케이션에서 ***불변*** 이벤트 로그를 저장. 이벤트 로그를 이용해서 현재 상태를 만드는 것. 
  - 중요한 것은 이벤트 로그를 수정, 삭제하는 것은 권장하지 않거나 금지.

#### 이벤트 로그에서 현재 상태 파생하기
- 이벤트 소싱을 사용하는 애플리케이션은 시스템에 기록한 데이터를 표현한 이벤트 로그를 가져와 사용자에게 보여주기에 적당한 애플리케이션 상태로 변환해야 한다
  - 중요한 것은 이 변환 과정은 ***결정적(deterministic)*** 이어야 한다. => 다시 수행하더라도 결과가 같아야 한다.
- 애플리케이션 레벨에서 제어하기 때문에 로그 컴팩션이 불가.

#### 명령과 이벤트
- 이벤트 소싱철학에서는 이벤트와 명령을 구별해야 하는데, 사용자 요청이 처음 도착했을때 이 요청은 ***명령***. 
- 명령이 실행 가능한지 확인 후 명령이 승인되면 ***불변 이벤트***가 된다.
- 이벤트는 생성 시점에 ***사실 fact***이 된다.
- 이벤트 스트림 소비자는 이벤트를 거절하지 못한다. 소비자가 이벤트를 받은 시점에는 이벤트는 이미 불변 로그의 일부분이다. 따라서 명령의 유효성은 이벤트가 되기 전에 동기식으로 검증해야 한다.

### 상태와 스트림 그리고 불변성
- 불변성은 입력이 변경되지 않으면 얼마든지 실험적인 처리 작업이 가능하다는 장점이 있다.
- 이벤트 상태는 시간에 따른 이벤트 스트림을 적분해서 구할 수 있다.
- 변경 스트림은 시간으로 상태를 미분해서 구할 수 있다.
- 변경 로그를 지속성 있께 저장한다면 상태를 간단히 재생성 할수 있는 효과가 있다. 모든 변경 가능 상태를 이벤트 로그로부터 파생된 것으로 생각하면 시스템을 거치는 데이터 흐름에 관해 추론하기 쉽다.

#### 불변 이벤트의 장점
- 예로부터 회계에서는 ***원장***을 이용해서 불변하게 처리해왔다. 원장을 지우거나 수정하지 않고, 실수를 보완하는 거래내역을 추가.
- 버그가 있는 코드를 배포해서 데이터에 잘못된 데이터를 기록했을 때 코드가 데이터를 덮어쓰면 복구하기가 매우 어렵다. But, 불변 이벤트 로그를 썼다면 문제 상황의 진단과 복구가 훨씬 쉽다.
- 불변 이벤트는 현재 상태보다 훨씬 많은 정보를 포함
  - ex) 유저 동작 히스토리

#### 동일한 이벤트 로그로 여러가지 뷰 만들기
- 불변 이벤트 로그에서 가변 상태를 분리하면 동일한 이벤트 로그로 다른 여러 읽기 전용 뷰를 만들 수 있다.
- CQRS(command query responsibility segregation): 데이터를 쓰는 형식과 읽는 형식을 분리해 다양한 읽기 뷰를 허용하는 것 

#### 동시성 제어
- 이벤트 소싱과 CDC의 가장 큰 단점은 이벤트 로그의 소비가 대개 비동기로 이루어진다는 점. => 이벤트를 썼지만, 읽기에서는 보여지지 않을 수 있다.
- 해결책 하나는 읽기 뷰의 갱신과 로그에 이벤트를 추가하는 작업을 동기식으로 수행하는 방법
  - 이 방법을 쓰려면 트랜잭션에서 여러 쓰기를 원자적 단위로 결합해야 하므로 이벤트 로그와 읽기 뷰를 같은 저장시스템에 담아야 한다.
  - 다른 시스템이면 분산 트랜잭션 필요
- 반면 이벤트 로그로 현재 상태를 만들면 동시성 제어가 단순해진다.
- 이벤트 로그와 애플리케이션 상태를 같은 방식으로 파티셔닝하면 단일 스레드 로그 소비자는 쓰기용 동시성 제어를 하지 않아도 된다.

#### 불변성의 한계
영구적으로 모든 변화의 불변 히스토리를 유지하는 것이 어느정도까지 가능할까?
- 대부분 데이터 추가하고 갱신, 삭제가 드물면 불면으로 만드는 것이 쉽지만, 그렇지 않다면, 데이터가 너무 커지거나 파편화 문제가 발생할수도 있다.
- 성능적인 이유 외에도 관리상의 이류 데이터를 삭제해야 할수 있다. ex) 개인정보 삭제 - 이거는 삭제 이벤트 추가하는 것으로 해결되지 않는다. 진짜 삭제해야 한다. 

## 스트림 처리
스트림을 처리하는 방법
- CQRS 패턴. ex) cache, 검색 색인 등
- 이벤트를 사용자에게 직접 보낸다. ex) email, push 등
- 하나 이상의 입력 스트림을 처리해 하나 이상의 출력 스트림을 생산한다.
이번에는 3번쨰 케이스에 대해서 설명할 예정

스크림을 처리한느 코드 조각을 ***operator*** or ***job*** 이라 부른다. 

### 스트림 처리의 사용
- 복잡한 이벤트 처리(complex event processing, CEP)
  - 특정 이벤트 패턴을 검색해야 하는 애플리케이션에 특히 적합
  - 질의는 처리 엔진에 제출하고 처리 엔진은 입력 스트림을 소비해 필요한 매칭을 수행하는 상태 기계를 내부적으로 유지하다가, 해당 매치를 발견하면 엔진에서 감지한 이벤트 패턴의 세부사항을 포함하는 complex event를 방출

- 스트림 분석
  - 대량의 이벤트를 집계하고 통계쩍 지표를 뽑는 것
  - ex) 특정 유형의 이벤트 빈도 측정, rolling average 계산, 이전 window와 비교해서 이상한 지표 감지하기.
  - 확률적 알고리즘을 사용하기도 한다. ex) bloom filter, hyperloglog 등

- 구체화 뷰 유지하기
- 스트림 상에서 검색하기
- 메시지 전달과 RPC

### 시간에 관한 추론
일괄처리는 이벤트 내부의 시간을 사용하기 때문에 문제가 없지만, 스트림에서는 장비의 시스템 시계를 이용한다. 간단하지만 이벤트 처리 시간이 지연되면 문제가 생긴다.

#### 이벤트 시간 vs 처리 시간 
이벤트 시간이 아니라 처리 시간으로 데이터를 생성하면 비정상적인 데이터가 보여질수 있다. 
- ex) request rate가 실제로는 일정하지만, stream processor가 잠시 멈췄다가 다시 처리하면, 밀려있던 event를 처리하면서 request rate가 튀는것처럼 보일수 있다.

#### 준비 여부 인식
window 안에 이벤트가 전부 들어오고 처리가 완료되었는지 판단하는 것이 어렵다. (이벤트 지연 등의 이슈가 있을 수 있다.) 

window를 이미 종료한 후에 도착한 낙오자 이벤트를 처리하는 방법
- 낙오자 이벤트 무시
- 수정 값을 발행

#### 어쨌든 어떤 시계를 사용할 것인가?
장치가 오프라인이었다가 온라인이 되었을때 이벤트를 전송하는 경우(극단적으로 지연된 낙오자 이벤트), 어떻게 해야하나? 장치의 로컬시계는 신뢰할수 없고, 뒤늦게 이벤트가 들어오기 때문에 서버시계를 사용하기도 어렵다. 

세가지 타임스탬프를 로그에 남긴다.
1. 이벤트가 발생한 시간. 장치 시계 
2. 이벤트를 전송한 시간. 장치 시계
3. 이벤트를 받은 시간. 서버 시계
2, 3번의 시간의 차이를 이용해서 offset을 추정할 수 있고, 그러면 1번의 시간에 offset을 적용해서 실제 발생 시간을 추정할 수 있다.

#### 윈도우 유형
- Tumbling window: 고정 길이, 모든 이벤트는 정확히 한 윈도우에 속한다. 
  - ex) 1분 tumbling window. 10:00:00 ~ 10:00:59, 10:01:00 ~ 10:01:59
- Hopping window: 고정 길이, 윈도우 중첩 가능. 
  - ex) 5분 hopping window. 10:03:00 ~ 10:07:59, 10:04:00 ~ 10:08:59
- Sliding window: 각 시간 간격 사이에서 발생한 모든 이벤트를 포함. 
  - ex) 5분 sliding window. 10:03:39 ~ 10:08:12, tumbling, hopping은 사이즈가 고정되어있어서 이러한 이벤트를 같이 집계할 수 없다.
- Session window: 고정된 기간이 없다. 같은 사용자가 짧은 시간동안 발생시킨 모든 이벤트를 그룹화, 사용자가 비활성화되면 윈도우 종료

### 스트림 조인
#### 스트림 스트림 조인
ex) session id를 공유하는 여러 이벤트의 join 
- stream processor가 state를 유지하는 방법으로 처리
  - 어느 시간동안? - 윈도우 적정크기 설정 필요
#### 스트림 테이블 조인(스트림 강화(enriching))
ex) 사용자 활동 이벤트에 사용자의 프로필 정보 추가 => enriching
- 이벤트마다 데이터베이스 조회 => 느리고, 데이터베이스에 부하 줄수 있다.
- stream processor 로컬에 db 복제본을 가지고 있음 like hash join 
  - local에 적재할수 있을만큼 데이터가 작아야 가능
  - 데이터가 변경될 수 있기 때문에 최신상태로 유지해야 한다. => CDC 이용해서 해결 가능
  
#### 테이블 테이블 조인 (구체화 뷰 유지)
ex) 트위터 타임라인 캐시
- 테이블 둘다 스트림으로 받아서 양쪽 다 스트림-테이블 조인처럼 처리해서 두 테이블을 조인한 구체화 뷰의 변경 스트림을 만든다.

#### 조인의 시간 의존성
시간에 따라 변하는 상태를 조인해야 한다면 어느 시점을 조인에 사용해야 할까? ex) 송장 세율 문제.

이 문제를 데이터웨어하우스에서는 천천히 변하는 차원(slowly chaning dimension, SCD)라고 한다. 이 문제는 흔히 조인되는 레코드의 특번 버전을 가리키는 데 유일한 식별자를 사용해 해결.

### 내결함성
일괄 처리에서는 결함 발생시, 다시 재시작하면 쉽게 해결할 수 있다. 재시작한다는 것은 레코드를 여러번 처리할수 있지만 출력은 한번만 처리된 것으로 보이는 효과가 나타난다.(exactly once sematics)

스트림에서 이렇게 하려면?

#### 마이크로 일괄 처리와 체크포인트
- 마이크로 일괄처리(microbatching): 아주 짧은 배치 작업으로 처리.(1s단위)
- 아파치 플링크는 주기적으로 상태의 롤링 체크포인트를 생성하고 지속성 있는 저장소에 저장한다. 장애 발생시 최근 체크포인트에서 재시작하고, 체크포인트와 장애 발생 사이의 출력은 버린다.

#### 원자적 커밋 재검토
장애가 발생했을 떄 정확히 한번 처리되는 것처럼 보일려면 처리가 성공했을 때만 모든 출력과 이벤트 처리의 부수효과가 발생하게 해야 한다. 

분산 트랜잭션에서 이 문제를 다뤘었는데, 좀 더 제한된 환경에서 원자적 커밋을 효율적으록 구현하는 것이 가능하다.

스트림 처리 프레임워크 내에서 상태 변화와 메시지를 관리해 트랜잭션을 내부적으로 유지한다.

#### 멱등성
여러번 수행하더라도 한번 수행한것과 같은 효과를 내게 하는 것.

#### 실패 후에 상태 재구축하기
윈도우 집계나 조인용 테이블과 색인처럼 상태가 필요한 스트림 처리는 실패 후에도 해당 상태가 복구됨을 보장해야 한다.

한가지 방법은 원격 데이터 저장소에 상태를 유지하고 복제하는 것.